{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (18, 10)\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "# Keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Adversarial Robustness Toolbox\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent\n",
    "\n",
    "# Other modules\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "# ART complains if we don't use this\n",
    "import tensorflow\n",
    "tensorflow.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what we did in Project 1, we will now define some constant for the path to annotations and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path('../data')\n",
    "IMG_FOLDER = Path(DATA_FOLDER / 'tsrd-train')\n",
    "ANNOTATIONS = Path(DATA_FOLDER / 'TsignRecgTrain4170Annotation.txt')\n",
    "COL_NAMES = ['filename','width','height','x1','y1','x2','y2','label']\n",
    "MODEL_FOLDER = Path('../Part 1')\n",
    "MODEL = Path(MODEL_FOLDER / 'chinese_traffic_sign_classifier_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ANNOTATIONS, names=COL_NAMES, sep=';', header=None, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the model we created in Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 16:39:46.326929: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2021-10-07 16:39:46.327018: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: CPU00370U\n",
      "2021-10-07 16:39:46.327037: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: CPU00370U\n",
      "2021-10-07 16:39:46.327214: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.91.3\n",
      "2021-10-07 16:39:46.327280: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.91.3\n",
      "2021-10-07 16:39:46.327296: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.91.3\n",
      "2021-10-07 16:39:46.392331: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "classifier = load_model(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ART library uses its own format for a model, so we need to create a new one that takes our model as an input. Following hints for additional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_art = KerasClassifier(model=classifier, clip_values=(0.0, 1.0), use_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create the adversarial examples, we will first import all the images. We use the same function calls from Project 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob(str(IMG_FOLDER) + '/*.png')\n",
    "IMG_SIZE = (134,128)\n",
    "\n",
    "dataset = []\n",
    "labels = []\n",
    "\n",
    "for idx in range(len(images)):\n",
    "    full_img_path = images[idx]\n",
    "    filename = Path(full_img_path).name\n",
    "    img_bgr = cv2.imread(full_img_path)\n",
    "    image = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, IMG_SIZE)\n",
    "    image = img_to_array(image)\n",
    "    dataset.append(image)\n",
    "    # get label specific to this image\n",
    "    row = df[df['filename'] == filename]\n",
    "    label = row['label'].values[0]\n",
    "    if row.empty:\n",
    "        print(filename)\n",
    "    else:\n",
    "        labels.append(label)\n",
    "\n",
    "dataset = np.array(dataset) / 255.0\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving the model as we did in Project 1, we will create the split between training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, valid_X, train_Y, valid_Y) = train_test_split(dataset, labels,\n",
    "                                                        test_size=0.2, stratify=labels)\n",
    "\n",
    "np.savez('../data/chinese_traffic_sign_dataset_2.npz', train_X=train_X, valid_X=valid_X,\n",
    "         train_Y=train_Y, valid_Y=valid_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we are now ready to generate malicious examples from the training data. We will use the two methods presented in the milestone description, and we will compare them with the original data points as well as with examples corrupted with random uniform noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "adv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
