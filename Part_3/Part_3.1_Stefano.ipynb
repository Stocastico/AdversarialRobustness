{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72309ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (18, 10)\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "# Keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Adversarial Robustness Toolbox\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent\n",
    "\n",
    "# Other modules\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "# ART complains if we don't use this\n",
    "import tensorflow as tf\n",
    "tensorflow.compat.v1.disable_eager_execution()\n",
    "\n",
    "# CleverHans stuff\n",
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from cleverhans.tf2.attacks.basic_iterative_method import basic_iterative_method\n",
    "from cleverhans.tf2.attacks.carlini_wagner_l2 import carlini_wagner_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f4113",
   "metadata": {},
   "source": [
    "Similar to what we did in Project 1, we will now define some constant for the path to annotations and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c962c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path('../data')\n",
    "IMG_FOLDER = Path(DATA_FOLDER / 'tsrd-train')\n",
    "ANNOTATIONS = Path(DATA_FOLDER / 'TsignRecgTrain4170Annotation.txt')\n",
    "COL_NAMES = ['filename','width','height','x1','y1','x2','y2','label']\n",
    "MODEL_FOLDER = Path('../Part_1')\n",
    "MODEL = Path(MODEL_FOLDER / 'chinese_traffic_sign_classifier_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349dabd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-25 16:33:50.336627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-25 16:33:50.439426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-25 16:33:50.440516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-25 16:33:50.508243: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-25 16:33:50.508715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-25 16:33:50.509041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-25 16:33:50.509261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-25 16:33:52.282650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-25 16:33:52.282975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-25 16:33:52.283240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-25 16:33:52.283466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2785 MB memory:  -> device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(ANNOTATIONS, names=COL_NAMES, sep=';', header=None, index_col=False)\n",
    "classifier = load_model(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6997aad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_input (InputLayer)    [(None, 128, 134, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 124, 130, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 22, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 58)                3770      \n",
      "=================================================================\n",
      "Total params: 64,666\n",
      "Trainable params: 64,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "new_classifier = tf.keras.Model(classifier.input, classifier.layers[-1].output)\n",
    "print(new_classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf79392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 130, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 22, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 58)                3770      \n",
      "=================================================================\n",
      "Total params: 64,666\n",
      "Trainable params: 64,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e112bd3",
   "metadata": {},
   "source": [
    "In order to create the adversarial examples, we will first import all the images. We use the same function calls from Project 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c610f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob(str(IMG_FOLDER) + '/*.png')\n",
    "IMG_SIZE = (134,128)\n",
    "\n",
    "dataset = []\n",
    "labels = []\n",
    "\n",
    "for idx in range(len(images)):\n",
    "    full_img_path = images[idx]\n",
    "    filename = Path(full_img_path).name\n",
    "    img_bgr = cv2.imread(full_img_path)\n",
    "    image = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, IMG_SIZE)\n",
    "    image = img_to_array(image)\n",
    "    dataset.append(image)\n",
    "    # get label specific to this image\n",
    "    row = df[df['filename'] == filename]\n",
    "    label = row['label'].values[0]\n",
    "    if row.empty:\n",
    "        print(filename)\n",
    "    else:\n",
    "        labels.append(label)\n",
    "\n",
    "dataset = np.array(dataset) / 255.0\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a79ba",
   "metadata": {},
   "source": [
    "Before saving the model as we did in Project 1, we will create the split between training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59b28246",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, valid_X, train_Y, valid_Y) = train_test_split(dataset, labels,\n",
    "                                                        test_size=0.2, stratify=labels)\n",
    "\n",
    "np.savez('../data/chinese_traffic_sign_dataset_3.npz', train_X=train_X, valid_X=valid_X,\n",
    "         train_Y=train_Y, valid_Y=valid_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908fed5",
   "metadata": {},
   "source": [
    "Let's check the accuracy of the models on the validation set we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fce62e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation dataset: 98.32%\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(valid_X)\n",
    "acc_base = np.sum(np.argmax(predictions, axis=1) == np.argmax(valid_Y, axis=1)) / len(valid_Y)\n",
    "print(f\"Accuracy on validation dataset: {acc_base * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3658e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "adv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
