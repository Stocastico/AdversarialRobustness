{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training\n",
    "\n",
    "__Objective__: Mitigate the model with **targeted attacks** using **Cleverhans** attack library.\n",
    "\n",
    "__Workflow__:\n",
    "1.  Load the `Traffic Sign` dataset and examine its structure.\n",
    "    - Download `tsrd-train` from http://www.nlpr.ia.ac.cn/pal/trafficdata/recognition.html.\n",
    "    - Take a closer look at the data inspecting it's size, shape, and quantity.\n",
    "    - View some random samples using either OpenCV or Matplotlib (or others) of the handwritten digits and observe the complexity of the images. Do you have any issues identify these written numbers?\n",
    "2. Using `numpy` or other libraries prepare your dataset for training\n",
    "    - Ensure the format or shape of the data is appropriate for input into your model (one-hot-encoding is needed for the labels)\n",
    "    - Ensure data types are correct and that data is normalized. \n",
    "3. Load and convert the model that is trained in the previous project\n",
    "   - load using Keras' `load_model` method\n",
    "   - convert it to logit model using `tf.keras.Model` with `model.input` as the input parameter and `model.layers[-1].output` as the output parameter.\n",
    "4. Generate malicious inputs\n",
    "   - FGSM attack\n",
    "      - Generate malicious inputs based on X_train and FGSM attack using CleverHans' `fast_gradient_method` class with 0.08 epsilon value\n",
    "5. Adversarial training\n",
    "   - Create a loop. In each iteration; \n",
    "      - generate new malicious inputs for the DL model.\n",
    "      - Merge the generated malicious with the training dataset\n",
    "      - Retraind the model using `model.fit` method with the new training dataset\n",
    "   - Save the new defended model\n",
    "6. Select first 8 images from test dataset, Plot random 24 images (e.g. 3 rows and 8 columns).\n",
    "   - First row shows the original images with the predicted labels\n",
    "   - Second row shows the FGSM based manipulated images with the predicted labels\n",
    "   - Third row shows the `random uniform` manipulated images with the predicted labels\n",
    "7. Generate malicious inputs based on X_train and FGSM attack using CleverHans' `fast_gradient_method` class with 0.08 epsilon value with target class `16`\n",
    "\n",
    "__Deliverable__:\n",
    "\n",
    "The deliverable is a Jupyter Notebook documenting your workflow. You should save `trainX,testX,trainY,testY,predictions,x_test_adv_fgsm,y_test_adv_fgsm,y_adv_pred_fgsm_hat` numpy matrices as you'll need it for further analysis in the second milestone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "\n",
    "from keras.models import load_model\n",
    "from art.estimators.classification import KerasClassifier\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from keras.preprocessing.image import  img_to_array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "IMAGE_PATH_TRAIN = '../../data/tsrd-train/'\n",
    "COL_NAMES = ['filename','f1','f2','x1','y1','x2','y2','label']\n",
    "IMAGE_SIZE = (134,128)\n",
    "EPOCHS = 30\n",
    "BS = 100\n",
    "MODEL_NAME = 'cnn-traffic-sign.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee060acb6c2c45809fb5b18ec785faad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2\n",
    "df = pd.read_csv('../../data/TsignRecgTrain4170Annotation.txt',names=COL_NAMES,sep=';', index_col=False)\n",
    "\n",
    "files = glob(IMAGE_PATH_TRAIN + '*.png')\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for fname in tqdm(range(len(files)),):\n",
    "    fname = files[fname]\n",
    "    image = cv2.imread(fname)\n",
    "    image = cv2.resize(image, IMAGE_SIZE)\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    \n",
    "    label = df.query(\"filename=='\" + os.path.split(fname)[1] + \"'\").label.values[0]\n",
    "    labels.append(label)\n",
    "    \n",
    "data = np.array(data) / 255.0\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 11:12:19.008968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 11:12:19.014489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 11:12:19.014772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 11:12:19.015297: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-09 11:12:19.015503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 11:12:19.015786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 11:12:19.016016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 11:12:19.313529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 11:12:19.313858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 11:12:19.314089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 11:12:19.314288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3000 MB memory:  -> device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "MODEL_NAME = '../../Part_1/chinese_traffic_sign_classifier_v1.h5'\n",
    "model = load_model(MODEL_NAME)\n",
    "# Create the logit model from tf.keras.Model\n",
    "logits_model = tf.keras.Model(model.input, model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 11:12:29.612827: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-09 11:12:29.949853: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2021-12-09 11:12:30.193771: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 26.258992805755394%\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testX)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(testY, axis=1)) / len(testY)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Attack results on undefended DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 11:13:16.848944: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.38GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-09 11:13:17.415008: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.42GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Generate adversarial test examples with **targeted Projected Gradient Descent** attack\n",
    "ATTACK_POWER = 0.1\n",
    "NUM_OF_MALICIOUS_INPUTS = 150\n",
    "TARGET_CLASS = 15\n",
    "\n",
    "randIdx = np.random.randint(0,testX.shape[0],NUM_OF_MALICIOUS_INPUTS)\n",
    "\n",
    "y_attack_target = (np.ones((NUM_OF_MALICIOUS_INPUTS,)) * TARGET_CLASS).astype(int)\n",
    "\n",
    "x_test_adv_pgd = projected_gradient_descent(logits_model, testX[randIdx,:],\n",
    "                                            eps=ATTACK_POWER, norm=np.inf, nb_iter=400, \n",
    "                                            eps_iter=ATTACK_POWER/10.0, targeted=True,\n",
    "                                            y=y_attack_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial attack success ratio\n",
    "Here, we will evaluate the **undefended** DL model for the PGD based malicious inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack success ratio on first 150 adversarial test samples: 64.66666666666666%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the the classifier on adversarial test examples\n",
    "y_adv_pred_pgd = model.predict(x_test_adv_pgd)\n",
    "attack_success_ratio = np.sum(np.argmax(y_adv_pred_pgd, axis=1) == TARGET_CLASS) / NUM_OF_MALICIOUS_INPUTS\n",
    "print(\"Attack success ratio on first {} adversarial test samples: {}%\".format(NUM_OF_MALICIOUS_INPUTS, attack_success_ratio*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Adversarial Training\n",
    "We will try to defen the DL model for PGD based malicious inputs with target class 15. The number of iteration is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5633f9fd124fd980db4ccdf4f2eb2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 11:18:35.471125: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 12.85MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-09 11:18:45.474346: W tensorflow/core/common_runtime/bfc_allocator.cc:457] Allocator (GPU_0_bfc) ran out of memory trying to allocate 880.0KiB (rounded to 901120)requested by op gradient_tape/sequential/max_pooling2d_1/MaxPool/MaxPoolGrad\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2021-12-09 11:18:45.474420: I tensorflow/core/common_runtime/bfc_allocator.cc:1004] BFCAllocator dump for GPU_0_bfc\n",
      "2021-12-09 11:18:45.474459: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (256): \tTotal Chunks: 54, Chunks in use: 54. 13.5KiB allocated for chunks. 13.5KiB in use in bin. 3.1KiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474485: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (512): \tTotal Chunks: 6, Chunks in use: 6. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 3.5KiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474509: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (1024): \tTotal Chunks: 3, Chunks in use: 3. 3.2KiB allocated for chunks. 3.2KiB in use in bin. 2.2KiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474531: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474553: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474580: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (8192): \tTotal Chunks: 7, Chunks in use: 6. 83.0KiB allocated for chunks. 74.5KiB in use in bin. 71.6KiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474605: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (16384): \tTotal Chunks: 2, Chunks in use: 1. 49.2KiB allocated for chunks. 19.0KiB in use in bin. 14.5KiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474630: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (32768): \tTotal Chunks: 4, Chunks in use: 3. 169.8KiB allocated for chunks. 137.8KiB in use in bin. 98.0KiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474655: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (65536): \tTotal Chunks: 3, Chunks in use: 3. 313.5KiB allocated for chunks. 313.5KiB in use in bin. 300.0KiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474679: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (131072): \tTotal Chunks: 5, Chunks in use: 5. 680.0KiB allocated for chunks. 680.0KiB in use in bin. 640.0KiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474700: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474724: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (524288): \tTotal Chunks: 6, Chunks in use: 5. 4.68MiB allocated for chunks. 3.95MiB in use in bin. 3.94MiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474745: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.22MiB allocated for chunks. 1.22MiB in use in bin. 1.22MiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474765: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 1. 3.14MiB allocated for chunks. 3.14MiB in use in bin. 3.14MiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474784: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474804: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474830: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (16777216): \tTotal Chunks: 3, Chunks in use: 3. 88.33MiB allocated for chunks. 88.33MiB in use in bin. 88.33MiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474855: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 2. 85.54MiB allocated for chunks. 85.54MiB in use in bin. 60.93MiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474874: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474898: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474920: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 4. 2.75GiB allocated for chunks. 2.75GiB in use in bin. 2.67GiB client-requested in use in bin.\n",
      "2021-12-09 11:18:45.474945: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] Bin for 880.0KiB was 512.0KiB, Chunk State: \n",
      "2021-12-09 11:18:45.474984: I tensorflow/core/common_runtime/bfc_allocator.cc:1033]   Size: 755.2KiB | Requested Size: 4.0KiB | in_use: 0 | bin_num: 11, prev:   Size: 128.0KiB | Requested Size: 128.0KiB | in_use: 1 | bin_num: -1, next:   Size: 3.14MiB | Requested Size: 3.14MiB | in_use: 1 | bin_num: -1\n",
      "2021-12-09 11:18:45.475002: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Next region of size 3146317824\n",
      "2021-12-09 11:18:45.475028: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000000 of size 256 next 1\n",
      "2021-12-09 11:18:45.475046: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000100 of size 1280 next 2\n",
      "2021-12-09 11:18:45.475061: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000600 of size 256 next 3\n",
      "2021-12-09 11:18:45.475075: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000700 of size 256 next 4\n",
      "2021-12-09 11:18:45.475089: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000800 of size 256 next 5\n",
      "2021-12-09 11:18:45.475103: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000900 of size 256 next 6\n",
      "2021-12-09 11:18:45.475117: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000a00 of size 256 next 9\n",
      "2021-12-09 11:18:45.475131: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000b00 of size 256 next 10\n",
      "2021-12-09 11:18:45.475145: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000c00 of size 256 next 11\n",
      "2021-12-09 11:18:45.475159: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000d00 of size 256 next 14\n",
      "2021-12-09 11:18:45.475173: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000e00 of size 256 next 15\n",
      "2021-12-09 11:18:45.475187: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0000f00 of size 256 next 18\n",
      "2021-12-09 11:18:45.475202: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0001000 of size 256 next 19\n",
      "2021-12-09 11:18:45.475216: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0001100 of size 256 next 20\n",
      "2021-12-09 11:18:45.475231: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0001200 of size 10240 next 17\n",
      "2021-12-09 11:18:45.475245: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0003a00 of size 102400 next 87\n",
      "2021-12-09 11:18:45.475261: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e001ca00 of size 131072 next 82\n",
      "2021-12-09 11:18:45.475276: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e003ca00 of size 105472 next 22\n",
      "2021-12-09 11:18:45.475290: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0056600 of size 256 next 16\n",
      "2021-12-09 11:18:45.475304: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0056700 of size 256 next 13\n",
      "2021-12-09 11:18:45.475318: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0056800 of size 256 next 24\n",
      "2021-12-09 11:18:45.475333: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0056900 of size 256 next 25\n",
      "2021-12-09 11:18:45.475347: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0056a00 of size 256 next 26\n",
      "2021-12-09 11:18:45.475363: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0056b00 of size 256 next 27\n",
      "2021-12-09 11:18:45.475377: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0056c00 of size 256 next 28\n",
      "2021-12-09 11:18:45.475391: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0056d00 of size 256 next 29\n",
      "2021-12-09 11:18:45.475406: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0056e00 of size 256 next 30\n",
      "2021-12-09 11:18:45.475420: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0056f00 of size 768 next 35\n",
      "2021-12-09 11:18:45.475435: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0057200 of size 256 next 41\n",
      "2021-12-09 11:18:45.475449: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0057300 of size 256 next 42\n",
      "2021-12-09 11:18:45.475463: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0057400 of size 256 next 43\n",
      "2021-12-09 11:18:45.475477: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0057500 of size 256 next 72\n",
      "2021-12-09 11:18:45.475491: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0057600 of size 256 next 45\n",
      "2021-12-09 11:18:45.475506: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0057700 of size 256 next 53\n",
      "2021-12-09 11:18:45.475522: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0057800 of size 1024 next 48\n",
      "2021-12-09 11:18:45.475536: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0057c00 of size 768 next 49\n",
      "2021-12-09 11:18:45.475551: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0057f00 of size 256 next 47\n",
      "2021-12-09 11:18:45.475565: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058000 of size 256 next 58\n",
      "2021-12-09 11:18:45.475579: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058100 of size 256 next 46\n",
      "2021-12-09 11:18:45.475593: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058200 of size 256 next 52\n",
      "2021-12-09 11:18:45.475608: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058300 of size 256 next 51\n",
      "2021-12-09 11:18:45.475622: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058400 of size 256 next 44\n",
      "2021-12-09 11:18:45.475636: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058500 of size 256 next 56\n",
      "2021-12-09 11:18:45.475650: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058600 of size 256 next 36\n",
      "2021-12-09 11:18:45.475664: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058700 of size 768 next 39\n",
      "2021-12-09 11:18:45.475679: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058a00 of size 256 next 69\n",
      "2021-12-09 11:18:45.475693: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058b00 of size 768 next 66\n",
      "2021-12-09 11:18:45.475708: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0058e00 of size 113152 next 80\n",
      "2021-12-09 11:18:45.475722: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0074800 of size 256 next 107\n",
      "2021-12-09 11:18:45.475736: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0074900 of size 256 next 92\n",
      "2021-12-09 11:18:45.475751: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0074a00 of size 1024 next 7\n",
      "2021-12-09 11:18:45.475765: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0074e00 of size 256 next 54\n",
      "2021-12-09 11:18:45.475779: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0074f00 of size 256 next 55\n",
      "2021-12-09 11:18:45.475794: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0075000 of size 256 next 91\n",
      "2021-12-09 11:18:45.475808: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0075100 of size 256 next 99\n",
      "2021-12-09 11:18:45.475824: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0075200 of size 256 next 86\n",
      "2021-12-09 11:18:45.475838: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0075300 of size 256 next 34\n",
      "2021-12-09 11:18:45.475852: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0075400 of size 256 next 79\n",
      "2021-12-09 11:18:45.475867: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0075500 of size 256 next 102\n",
      "2021-12-09 11:18:45.475881: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0075600 of size 11264 next 97\n",
      "2021-12-09 11:18:45.475896: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0078200 of size 47616 next 106\n",
      "2021-12-09 11:18:45.475911: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0083c00 of size 32768 next 94\n",
      "2021-12-09 11:18:45.475925: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e008bc00 of size 60672 next 37\n",
      "2021-12-09 11:18:45.475940: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e009a900 of size 256 next 38\n",
      "2021-12-09 11:18:45.475954: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e009aa00 of size 256 next 103\n",
      "2021-12-09 11:18:45.475969: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e009ab00 of size 172032 next 57\n",
      "2021-12-09 11:18:45.475984: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00c4b00 of size 768 next 105\n",
      "2021-12-09 11:18:45.475999: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00c4e00 of size 19456 next 63\n",
      "2021-12-09 11:18:45.476015: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00c9a00 of size 15360 next 104\n",
      "2021-12-09 11:18:45.476029: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00cd600 of size 256 next 95\n",
      "2021-12-09 11:18:45.476044: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00cd700 of size 14848 next 12\n",
      "2021-12-09 11:18:45.476059: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00d1100 of size 768 next 84\n",
      "2021-12-09 11:18:45.476074: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00d1400 of size 9728 next 62\n",
      "2021-12-09 11:18:45.476088: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00d3a00 of size 256 next 89\n",
      "2021-12-09 11:18:45.476102: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00d3b00 of size 256 next 108\n",
      "2021-12-09 11:18:45.476117: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00d3c00 of size 256 next 61\n",
      "2021-12-09 11:18:45.476131: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00d3d00 of size 256 next 109\n",
      "2021-12-09 11:18:45.476145: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 7f44e00d3e00 of size 8704 next 32\n",
      "2021-12-09 11:18:45.476160: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e00d6000 of size 808960 next 67\n",
      "2021-12-09 11:18:45.476175: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e019b800 of size 131072 next 98\n",
      "2021-12-09 11:18:45.476191: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e01bb800 of size 1277952 next 8\n",
      "2021-12-09 11:18:45.476207: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e02f3800 of size 901120 next 40\n",
      "2021-12-09 11:18:45.476221: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 7f44e03cf800 of size 30976 next 64\n",
      "2021-12-09 11:18:45.476236: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e03d7100 of size 14848 next 90\n",
      "2021-12-09 11:18:45.476250: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 7f44e03dab00 of size 32768 next 65\n",
      "2021-12-09 11:18:45.476264: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e03e2b00 of size 131072 next 85\n",
      "2021-12-09 11:18:45.476279: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0402b00 of size 131072 next 74\n",
      "2021-12-09 11:18:45.476295: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 7f44e0422b00 of size 773376 next 78\n",
      "2021-12-09 11:18:45.476310: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e04df800 of size 3293184 next 75\n",
      "2021-12-09 11:18:45.476326: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e0803800 of size 54220800 next 50\n",
      "2021-12-09 11:18:45.476341: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e3bb9000 of size 30873600 next 59\n",
      "2021-12-09 11:18:45.476357: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f44e592a800 of size 717502464 next 68\n",
      "2021-12-09 11:18:45.476399: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f451056e000 of size 808960 next 21\n",
      "2021-12-09 11:18:45.476417: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f4510633800 of size 808960 next 33\n",
      "2021-12-09 11:18:45.476431: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f45106f9000 of size 808960 next 88\n",
      "2021-12-09 11:18:45.476447: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f45107be800 of size 35475456 next 93\n",
      "2021-12-09 11:18:45.476462: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f4512993800 of size 30873600 next 71\n",
      "2021-12-09 11:18:45.476476: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f4514705000 of size 717502464 next 77\n",
      "2021-12-09 11:18:45.476491: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f453f348800 of size 718303744 next 23\n",
      "2021-12-09 11:18:45.476506: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f456a04fa00 of size 30873600 next 101\n",
      "2021-12-09 11:18:45.476522: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7f456bdc1200 of size 799862272 next 18446744073709551615\n",
      "2021-12-09 11:18:45.476537: I tensorflow/core/common_runtime/bfc_allocator.cc:1065]      Summary of in-use Chunks by size: \n",
      "2021-12-09 11:18:45.476557: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 54 Chunks of size 256 totalling 13.5KiB\n",
      "2021-12-09 11:18:45.476575: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 6 Chunks of size 768 totalling 4.5KiB\n",
      "2021-12-09 11:18:45.476591: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 1024 totalling 2.0KiB\n",
      "2021-12-09 11:18:45.476607: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2021-12-09 11:18:45.476622: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 9728 totalling 9.5KiB\n",
      "2021-12-09 11:18:45.476639: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 10240 totalling 10.0KiB\n",
      "2021-12-09 11:18:45.476656: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 11264 totalling 11.0KiB\n",
      "2021-12-09 11:18:45.476673: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 14848 totalling 29.0KiB\n",
      "2021-12-09 11:18:45.476689: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 15360 totalling 15.0KiB\n",
      "2021-12-09 11:18:45.476705: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 19456 totalling 19.0KiB\n",
      "2021-12-09 11:18:45.476722: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 32768 totalling 32.0KiB\n",
      "2021-12-09 11:18:45.476738: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 47616 totalling 46.5KiB\n",
      "2021-12-09 11:18:45.476755: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 60672 totalling 59.2KiB\n",
      "2021-12-09 11:18:45.476772: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 102400 totalling 100.0KiB\n",
      "2021-12-09 11:18:45.476789: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 105472 totalling 103.0KiB\n",
      "2021-12-09 11:18:45.476805: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 113152 totalling 110.5KiB\n",
      "2021-12-09 11:18:45.476822: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 4 Chunks of size 131072 totalling 512.0KiB\n",
      "2021-12-09 11:18:45.476839: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 172032 totalling 168.0KiB\n",
      "2021-12-09 11:18:45.476855: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 4 Chunks of size 808960 totalling 3.09MiB\n",
      "2021-12-09 11:18:45.476872: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 901120 totalling 880.0KiB\n",
      "2021-12-09 11:18:45.476888: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 1277952 totalling 1.22MiB\n",
      "2021-12-09 11:18:45.476904: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 3293184 totalling 3.14MiB\n",
      "2021-12-09 11:18:45.476921: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 3 Chunks of size 30873600 totalling 88.33MiB\n",
      "2021-12-09 11:18:45.476938: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 35475456 totalling 33.83MiB\n",
      "2021-12-09 11:18:45.476955: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 54220800 totalling 51.71MiB\n",
      "2021-12-09 11:18:45.476971: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 717502464 totalling 1.34GiB\n",
      "2021-12-09 11:18:45.476988: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 718303744 totalling 685.03MiB\n",
      "2021-12-09 11:18:45.477005: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 799862272 totalling 762.81MiB\n",
      "2021-12-09 11:18:45.477021: I tensorflow/core/common_runtime/bfc_allocator.cc:1072] Sum Total of in-use chunks: 2.93GiB\n",
      "2021-12-09 11:18:45.477037: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] total_region_allocated_bytes_: 3146317824 memory_limit_: 3146317824 available bytes: 0 curr_region_allocation_bytes_: 6292635648\n",
      "2021-12-09 11:18:45.477065: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] Stats: \n",
      "Limit:                      3146317824\n",
      "InUse:                      3145472000\n",
      "MaxInUse:                   3145504768\n",
      "NumAllocs:                      877316\n",
      "MaxAllocSize:                868602112\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2021-12-09 11:18:45.477104: W tensorflow/core/common_runtime/bfc_allocator.cc:468] **************************************************************************************************xx\n",
      "2021-12-09 11:18:45.477183: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at pooling_ops_common.cc:457 : Resource exhausted: OOM when allocating tensor with shape[16,32,20,22] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[16,32,20,22] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/sequential/max_pooling2d_1/MaxPool/MaxPoolGrad (defined at tmp/ipykernel_17697/793370899.py:24) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_8497]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17697/2070005796.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my_train_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_adv_pgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     model.fit(x_train_tmp, y_train_tmp, epochs=100,verbose=0,callbacks=[es],\n\u001b[0m\u001b[1;32m     25\u001b[0m               validation_data=(x_test_adv_pgd, y_test_adv_pgd), batch_size=16)\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn-traffic-sign-defended-for-pgd.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/adv/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/adv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/adv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.virtualenvs/adv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/adv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.virtualenvs/adv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/adv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[16,32,20,22] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/sequential/max_pooling2d_1/MaxPool/MaxPoolGrad (defined at tmp/ipykernel_17697/793370899.py:24) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_8497]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Adversarial training\n",
    "NUM_OF_RETRAIN_ITER = 10\n",
    "\n",
    "y_test_adv_pgd = testY[randIdx,:]\n",
    "print(y_test_adv_pgd.shape)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   patience=5, \n",
    "                   min_delta=0.001,\n",
    "                   verbose=1,\n",
    "                   restore_best_weights=True,\n",
    "                   mode='min')\n",
    "\n",
    "for i in tqdm(range(NUM_OF_RETRAIN_ITER)):\n",
    "    logits_model = tf.keras.Model(model.input, model.layers[-1].output)\n",
    "    x_test_adv_pgd = projected_gradient_descent(logits_model, testX[randIdx,:],\n",
    "                                                eps=ATTACK_POWER, norm=np.inf, nb_iter=100, \n",
    "                                                eps_iter=ATTACK_POWER/10.0, targeted=True,\n",
    "                                                y=y_attack_target)\n",
    "    \n",
    "    x_train_tmp = np.concatenate((trainX, x_test_adv_pgd), axis=0)\n",
    "    y_train_tmp = np.concatenate((trainY, y_test_adv_pgd), axis=0)\n",
    "    \n",
    "    model.fit(x_train_tmp, y_train_tmp, epochs=100,verbose=0,callbacks=[es],\n",
    "              validation_data=(x_test_adv_pgd, y_test_adv_pgd), batch_size=16)\n",
    "model.save('cnn-traffic-sign-defended-for-pgd.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack success ratio on Defended model\n",
    "Now, we will evaluate the **defended** DL model for the PGD based malicious inputs. The result would be lower than attack success ratio on **undefended** DL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the the classifier on adversarial test examples\n",
    "x_test_adv_pgd = projected_gradient_descent(logits_model, testX[randIdx,:],\n",
    "                                            eps=ATTACK_POWER, norm=np.inf, nb_iter=100, \n",
    "                                            eps_iter=ATTACK_POWER/10.0, targeted=True,\n",
    "                                            y=y_attack_target)\n",
    "y_adv_pred_pgd = model.predict(x_test_adv_pgd)\n",
    "attack_success_ratio = np.sum(np.argmax(y_adv_pred_pgd, axis=1) == TARGET_CLASS) / NUM_OF_MALICIOUS_INPUTS\n",
    "print(\"Attack success ratio on first {} adversarial test samples: {}%\".format(NUM_OF_MALICIOUS_INPUTS, attack_success_ratio*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Plot original, noisy and malicious inputs\n",
    "NUM_OF_ROWS = 3\n",
    "NUM_OF_COLS = 8\n",
    "fig, ax = plt.subplots(NUM_OF_ROWS,NUM_OF_COLS, figsize=(15,6))\n",
    "\n",
    "for i in range(NUM_OF_COLS):\n",
    "    uniform_noise = np.random.uniform(low=-1.0,high=1.0,size=testX[i].shape) * ATTACK_POWER\n",
    "    noise = testX[i:i+1] + uniform_noise\n",
    "    \n",
    "    benign_pred = model.predict(testX[i:i+1])\n",
    "    malicious_pred = model.predict(x_test_adv_pgd[i:i+1])\n",
    "    noise_pred = model.predict(noise)\n",
    "\n",
    "    ax[0,i].imshow(testX[i])\n",
    "    ax[1,i].imshow(x_test_adv_pgd[i])\n",
    "    ax[2,i].imshow(noise[0].clip(0.0,1.0))\n",
    "\n",
    "    ax[0,i].set_title('Label:' + str(benign_pred.argmax(axis=1)))\n",
    "    ax[1,i].set_title('Label:' + str(malicious_pred.argmax(axis=1)))\n",
    "    ax[2,i].set_title('Label:' + str(noise_pred.argmax(axis=1)))\n",
    "    ax[0,i].axis('off')\n",
    "    ax[1,i].axis('off')\n",
    "    ax[2,i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack success ratio on Defended model with another target\n",
    "Now, we will evaluate the **defended** DL model for the PGD based malicious inputs for another target class (e.g. 16). The result would be higher than attack success ratio on **previous** target class. To protect the DL model for other target class based attacks, you need to perform adversarial training for the other class also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Attack success ratio on Defended model with another target\n",
    "NEW_TARGET_CLASS = 16\n",
    "y_attack_target_new = (np.ones((NUM_OF_MALICIOUS_INPUTS,)) * NEW_TARGET_CLASS).astype(int)\n",
    "\n",
    "x_test_adv_pgd = projected_gradient_descent(logits_model, testX[randIdx,:],\n",
    "                                            eps=ATTACK_POWER, norm=np.inf, nb_iter=100, \n",
    "                                            eps_iter=ATTACK_POWER/10.0, targeted=True,\n",
    "                                            y=y_attack_target_new)\n",
    "\n",
    "y_adv_pred_pgd = model.predict(x_test_adv_pgd)\n",
    "attack_success_ratio = np.sum(np.argmax(y_adv_pred_pgd, axis=1) == NEW_TARGET_CLASS) / NUM_OF_MALICIOUS_INPUTS\n",
    "print(\"Attack success ratio on first {} adversarial test samples: {}%\".format(NUM_OF_MALICIOUS_INPUTS, attack_success_ratio*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save matrices\n",
    "np.savez('milestone-4-1.npz', trainX=trainX, testX=testX,\n",
    "         trainY=trainY, testY=testY, predictions=predictions,\n",
    "         x_test_adv_pgd=x_test_adv_pgd,\n",
    "         y_test_adv_pgd=y_test_adv_pgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "adv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
